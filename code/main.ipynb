{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_uschad = pd.read_table(\"../data/USC-HAD/UCS-HAD_cleared.txt\", delimiter=',', header=None)\n",
    "data_uschad.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']\n",
    "\n",
    "data_wisdm = pd.read_table(\"../data/WISDM/WISDM_ar_v1.1_raw_cleared.txt\", delimiter=',', header=None)\n",
    "data_wisdm.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to construct 10 seconds time series. To do it we need to remember the following:\n",
    "* each time series should be from one user and one type of activity;\n",
    "* in the time series timestamp should't differ more then 0.2 second (empirical rule, in ideal all timestamp should differ on 50 ms = 0.05 second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create **object-feature** matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_candidate(candidate, data_type, threshold=2.*1e8):\n",
    "    if data_type == \"USCHAD\":\n",
    "        threshold = 0.\n",
    "    tsp = np.array(candidate['timestamp'])\n",
    "    diffs = tsp[1:] - tsp[:-1]\n",
    "    \n",
    "    return np.sum(diffs > threshold) == 0\n",
    "\n",
    "def get_time_series(accelerations, data_type, nb=200):\n",
    "    accelerations.index = [i for i in range(len(accelerations))]\n",
    "    TS = []\n",
    "    st = 0\n",
    "    fi = st + nb\n",
    "    while fi < len(accelerations):\n",
    "        candidate = accelerations.loc[[st + i for i in range(nb)], :]\n",
    "        if check_candidate(candidate, data_type):\n",
    "            TS.append([np.array(candidate['x']), \n",
    "                       np.array(candidate['y']), \n",
    "                       np.array(candidate['z'])])\n",
    "        st = fi\n",
    "        fi += nb\n",
    "    \n",
    "    return TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distribution(data, df):\n",
    "    classes = list(set(data['activity']))\n",
    "    for activity in classes:\n",
    "        nb = np.sum(df['activity'] == classes.index(activity))\n",
    "        print(\"{:<20}{:<9d}{:<5.2f} %\".format(activity, nb, 100. * nb / df.shape[0]))\n",
    "    print(\"\")\n",
    "    print(\"Number of objects: {:d}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(data, data_type, get_feature_names, get_features, params=[]):\n",
    "    \n",
    "    classes = list(set(data['activity']))\n",
    "    feature_names = get_feature_names(params)\n",
    "    df = pd.DataFrame(columns=['activity']+feature_names) \n",
    "\n",
    "    id_range = np.unique(np.array(data['id_user']))\n",
    "    for id_user in id_range:\n",
    "        for activity in classes:\n",
    "            mask = (data.loc[:, 'id_user'] == id_user) & (data.loc[:, 'activity'] == activity)\n",
    "            accelerations = data.loc[mask, ['timestamp', 'x', 'y', 'z']].copy()\n",
    "            TS = get_time_series(accelerations, data_type, nb=200)\n",
    "            for ts in TS:\n",
    "                features = get_features(ts, params)\n",
    "                df.loc[len(df), :] = [classes.index(activity)] + features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is the following: we will consider 10 seconds time series (or 200 points of measurements) and calculate 40 features:\n",
    "* ```[3]``` - mean acceleration of each axis;\n",
    "* ```[3]``` - std of acceleration of each axis;\n",
    "* ```[3]``` - mean absolute deviation of acceleration of each axis;\n",
    "* ```[1]``` - mean acceleration;\n",
    "* ```[30]``` - distribution of time series values of each axis. First of all we calculate min and max of each component ($X, Y, Z$) from the whole interval. Then we divide the range of values of each component into 10 equal intervals and calculate on each each interval the percent of values that are in it (in the corresponding interval).  \n",
    "\n",
    "And apply LogisticRegression and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expert_names(params):\n",
    "    feature_names = ['avg_x', 'avg_y', 'avg_z', \n",
    "                     'std_x', 'std_y', 'std_z', \n",
    "                     'abs_x', 'abs_y', 'abs_z', 'mean']\n",
    "    for i in range(10):\n",
    "        name = str(i) + '_'\n",
    "        feature_names += [name + 'x', name + 'y', name + 'z']\n",
    "        \n",
    "    return feature_names\n",
    "\n",
    "def get_expert_features(ts, params):\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    n = x.shape[0]\n",
    "    features = []\n",
    "    features.append(x.mean())\n",
    "    features.append(y.mean())\n",
    "    features.append(z.mean())\n",
    "    features.append(x.std())\n",
    "    features.append(y.std())\n",
    "    features.append(z.std())\n",
    "    features.append(np.abs(x - x.mean()).mean())\n",
    "    features.append(np.abs(y - y.mean()).mean())\n",
    "    features.append(np.abs(z - z.mean()).mean())\n",
    "    features.append((x+y+z).mean() / 3.)\n",
    "    x_range = np.linspace(x.min(), x.max(), 11)\n",
    "    y_range = np.linspace(y.min(), y.max(), 11)\n",
    "    z_range = np.linspace(z.min(), z.max(), 11)\n",
    "    for i in range(10):\n",
    "        features.append(1. * np.sum((x_range[i] <= x) & (x < x_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((y_range[i] <= y) & (y < y_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((z_range[i] <= z) & (z < z_range[i+1])) / n)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            229      5.30  %\n",
      "Walking             1917     44.36 %\n",
      "Upstairs            466      10.78 %\n",
      "Sitting             277      6.41  %\n",
      "Jogging             1075     24.88 %\n",
      "Downstairs          357      8.26  %\n",
      "\n",
      "Number of objects: 4321\n"
     ]
    }
   ],
   "source": [
    "df_expert_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_expert_names, get_expert_features)\n",
    "get_distribution(data_wisdm, df_expert_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            1167     8.57  %\n",
      "Elevator-up         764      5.61  %\n",
      "Walking-forward     1874     13.76 %\n",
      "Sitting             1294     9.50  %\n",
      "Walking-downstairs  951      6.98  %\n",
      "Sleeping            1860     13.66 %\n",
      "Elevator-down       763      5.60  %\n",
      "Walking-upstairs    1018     7.47  %\n",
      "Jumping             495      3.63  %\n",
      "Walking-right       1305     9.58  %\n",
      "Walking-left        1280     9.40  %\n",
      "Running             849      6.23  %\n",
      "\n",
      "Number of objects: 13620\n"
     ]
    }
   ],
   "source": [
    "df_expert_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_expert_names, get_expert_features)\n",
    "get_distribution(data_uschad, df_expert_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_autoregressive_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        feature_names += ['intercept_' + ax]\n",
    "        for i in range(n):\n",
    "            feature_names += ['coef_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_autoregressive_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "            Y[i] = axis[i+n]\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, Y)\n",
    "        features.append(lr.intercept_)\n",
    "        features.extend(lr.coef_)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            229      5.30  %\n",
      "Walking             1917     44.36 %\n",
      "Upstairs            466      10.78 %\n",
      "Sitting             277      6.41  %\n",
      "Jogging             1075     24.88 %\n",
      "Downstairs          357      8.26  %\n",
      "\n",
      "Number of objects: 4321\n"
     ]
    }
   ],
   "source": [
    "df_ar_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_autoregressive_names,\n",
    "                                 get_autoregressive_features, params)\n",
    "get_distribution(data_wisdm, df_ar_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            1167     8.57  %\n",
      "Elevator-up         764      5.61  %\n",
      "Walking-forward     1874     13.76 %\n",
      "Sitting             1294     9.50  %\n",
      "Walking-downstairs  951      6.98  %\n",
      "Sleeping            1860     13.66 %\n",
      "Elevator-down       763      5.60  %\n",
      "Walking-upstairs    1018     7.47  %\n",
      "Jumping             495      3.63  %\n",
      "Walking-right       1305     9.58  %\n",
      "Walking-left        1280     9.40  %\n",
      "Running             849      6.23  %\n",
      "\n",
      "Number of objects: 13620\n"
     ]
    }
   ],
   "source": [
    "df_ar_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_autoregressive_names,\n",
    "                                  get_autoregressive_features, params)\n",
    "get_distribution(data_uschad, df_ar_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrum_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        for i in range(n):\n",
    "            feature_names += ['eigv_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_spectrum_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "        h = sc.linalg.svd(X.T.dot(X), compute_uv=False, overwrite_a=True)\n",
    "        features.extend(h)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            229      5.30  %\n",
      "Walking             1917     44.36 %\n",
      "Upstairs            466      10.78 %\n",
      "Sitting             277      6.41  %\n",
      "Jogging             1075     24.88 %\n",
      "Downstairs          357      8.26  %\n",
      "\n",
      "Number of objects: 4321\n"
     ]
    }
   ],
   "source": [
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spectrum_names,\n",
    "                                  get_spectrum_features, params)\n",
    "get_distribution(data_wisdm, df_ssa_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            1167     8.57  %\n",
      "Elevator-up         764      5.61  %\n",
      "Walking-forward     1874     13.76 %\n",
      "Sitting             1294     9.50  %\n",
      "Walking-downstairs  951      6.98  %\n",
      "Sleeping            1860     13.66 %\n",
      "Elevator-down       763      5.60  %\n",
      "Walking-upstairs    1018     7.47  %\n",
      "Jumping             495      3.63  %\n",
      "Walking-right       1305     9.58  %\n",
      "Walking-left        1280     9.40  %\n",
      "Running             849      6.23  %\n",
      "\n",
      "Number of objects: 13620\n"
     ]
    }
   ],
   "source": [
    "df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spectrum_names,\n",
    "                                   get_spectrum_features, params)\n",
    "get_distribution(data_uschad, df_ssa_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_internal_score(clf, X, y, max_iter=20):\n",
    "    nb = np.unique(y).shape[0]\n",
    "    scores = np.zeros(nb+1)\n",
    "    for j in range(max_iter):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        scores[0] += accuracy_score(y_test, y_predict)\n",
    "        for i in range(nb):\n",
    "            scores[i+1] += accuracy_score(1*(np.array(y_test) == i), \n",
    "                                          1*(np.array(y_predict) == i))\n",
    "            \n",
    "    return scores / max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_score(df, estimator, params_grid, test_size=0.3):\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df['activity'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    clf = GridSearchCV(estimator, params_grid)\n",
    "    clf.fit(X_train, list(y_train))\n",
    "    clf_lr = clf.best_estimator_\n",
    "    scores = get_internal_score(clf_lr, X, list(y))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['l1', 'l2'], \n",
    "              'class_weight': ['balanced', None], \n",
    "              'C': 10. ** np.arange(0, 4, 1)}\n",
    "\n",
    "scores_wisdm = {}\n",
    "scores_uschad = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expert** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_expert_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_expert_names, get_expert_features)\n",
    "df_expert_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_expert_names, get_expert_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_expert'] = get_score(df_expert_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_expert'] = get_score(df_expert_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **autoregression model** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [10]\n",
    "n = params[0]\n",
    "\n",
    "df_ar_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_autoregressive_names,\n",
    "                                 get_autoregressive_features, params)\n",
    "df_ar_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_autoregressive_names, \n",
    "                                  get_autoregressive_features, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_ar_' + str(n)] = get_score(df_ar_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_ar_' + str(n)] = get_score(df_ar_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **spectrum analysis** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [10]\n",
    "n = params[0]\n",
    "\n",
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spectrum_names,\n",
    "                                 get_spectrum_features, params)\n",
    "df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spectrum_names, \n",
    "                                  get_spectrum_features, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_ssa_' + str(n)] = get_score(df_ssa_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_ssa_' + str(n)] = get_score(df_ssa_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_wisdm = pd.DataFrame.from_dict(scores_wisdm, orient='index')\n",
    "results_wisdm.columns = ['all'] + list(set(data_wisdm['activity']))\n",
    "\n",
    "results_uschad = pd.DataFrame.from_dict(scores_uschad, orient='index')\n",
    "results_uschad.columns = ['all'] + list(set(data_uschad['activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_wisdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_uschad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

\documentclass[a4paper,14pt]{article} 
% Этот шаблон документа разработан в 2014 году 
% Данилом Фёдоровых (danil@fedorovykh.ru) 
% для использования в курсе 
% «Документы и презентации в \LaTeX», записанном НИУ ВШЭ 
% для Coursera.org: http://coursera.org/course/latex . 
% Исходная версия шаблона —- 
% https://www.writelatex.com/coursera/latex/5.3 

% В этом документе преамбула 

%%% Работа с русским языком 
\usepackage{cmap} % поиск в PDF 
\usepackage{mathtext} % русские буквы в формулах 
\usepackage[T2A]{fontenc} % кодировка 
\usepackage[cp1251]{inputenc} % кодировка исходного текста 
\usepackage[english]{babel} % локализация и переносы 
\usepackage{indentfirst} 
\frenchspacing
\usepackage[shortlabels]{enumitem}

\renewcommand{\epsilon}{\ensuremath{\varepsilon}} 
\renewcommand{\phi}{\ensuremath{\varphi}} 
\renewcommand{\kappa}{\ensuremath{\varkappa}} 
\renewcommand{\le}{\ensuremath{\leqslant}} 
\renewcommand{\leq}{\ensuremath{\leqslant}} 
\renewcommand{\ge}{\ensuremath{\geqslant}} 
\renewcommand{\geq}{\ensuremath{\geqslant}} 
\renewcommand{\emptyset}{\varnothing} 
\newcommand{\T}{{\text{\footnotesize\sffamily\upshape\mdseries T}}}


%%% Дополнительная работа с математикой 
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools, bm} % AMS 
\usepackage{icomma} % "Умная" запятая: $0,2$ —- число, $0, 2$ —- перечисление 

%% Номера формул 
%\mathtoolsset{showonlyrefs=true} % Показывать номера только у тех формул, на которые есть \eqref{} в тексте. 
%\usepackage{leqno} % Нумереация формул слева 

%% Свои команды 
\DeclareMathOperator{\sgn}{\mathop{sgn}}
\DeclareMathOperator*{\argmin}{arg\,min}

%% Перенос знаков в формулах (по Львовскому) 
%\newcommand*{\hm}[1]{#1\nobreak\discretionary{} 
%	{\hbox{$\mathsurround=0pt #1$}}{}} 

%%% Работа с картинками 
\usepackage{graphicx} % Для вставки рисунков 
\graphicspath{{images/}{images2/}} % папки с картинками 
\setlength\fboxsep{3pt} % Отступ рамки \fbox{} от рисунка 
\setlength\fboxrule{1pt} % Толщина линий рамки \fbox{} 
\usepackage{wrapfig} % Обтекание рисунков текстом 
\usepackage{float}
\usepackage{subfig}

%%% Работа с таблицами 
\usepackage{array,tabularx,tabulary,booktabs} % Дополнительная работа с таблицами 
\usepackage{longtable} % Длинные таблицы 
\usepackage{multirow} % Слияние строк в таблице 

%%% Теоремы 
\theoremstyle{plain} % Это стиль по умолчанию, его можно не переопределять. 
\newtheorem{theorem}{Теорема}[section] 
\newtheorem{proposition}[theorem]{Утверждение}

\theoremstyle{definition} % "Определение" 
\newtheorem{corollary}{Следствие}[theorem] 
\newtheorem{problem}{Задача}[section] 

\theoremstyle{remark} % "Примечание" 
\newtheorem*{nonum}{Решение} 

%%% Программирование 
\usepackage{etoolbox} % логические операторы

%%% Страница 
\usepackage{extsizes} % Возможность сделать 14-й шрифт 
\usepackage{geometry} % Простой способ задавать поля 
\geometry{top=20mm} 
\geometry{bottom=25mm} 
\geometry{left=20mm} 
\geometry{right=20mm} 
% 
%\usepackage{fancyhdr} % Колонтитулы 
% \pagestyle{fancy} 
%\renewcommand{\headrulewidth}{0pt} % Толщина линейки, отчеркивающей верхний колонтитул 
% \lfoot{Нижний левый} 
% \rfoot{Нижний правый} 
% \rhead{Верхний правый} 
% \chead{Верхний в центре} 
% \lhead{Верхний левый} 
% \cfoot{Нижний в центре} % По умолчанию здесь номер страницы 

\usepackage{setspace} % Интерлиньяж 
\onehalfspacing % Интерлиньяж 1.5 
%\doublespacing % Интерлиньяж 2 
%\singlespacing % Интерлиньяж 1
\setlength{\parindent}{1cm}

\usepackage{lastpage} % Узнать, сколько всего страниц в документе. 

\usepackage{soul} % Модификаторы начертания 

\usepackage{hyperref} 
\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor} 
\hypersetup{ % Гиперссылки 
	unicode=true, % русские буквы в раздела PDF 
	pdftitle={Заголовок}, % Заголовок 
	pdfauthor={Автор}, % Автор 
	pdfsubject={Тема}, % Тема 
	pdfcreator={Создатель}, % Создатель 
	pdfproducer={Производитель}, % Производитель 
	pdfkeywords={keyword1} {key2} {key3}, % Ключевые слова 
	colorlinks=true, % false: ссылки в рамках; true: цветные ссылки 
	linkcolor=red, % внутренние ссылки 
	citecolor=black, % на библиографию 
	filecolor=magenta, % на файлы
	urlcolor=blue % на URL 
} 

\usepackage{csquotes} % Еще инструменты для ссылок 

%\usepackage[style=authoryear,maxcitenames=2,backend=biber,sorting=nty]{biblatex} 

\usepackage{multicol} % Несколько колонок 

\usepackage{tikz} % Работа с графикой 
\usepackage{pgfplots} 
\usepackage{pgfplotstable} 


\author
{Ilya Zharikov, Roman Isachenko, Artem Bochkarev} 
\title 
{Metamodels for complex structured objects classification}
\date{}

\begin{document} 
\maketitle

\section*{Introduction}
This project is dedicated to multiclass classification of complex structured objects (for which we don't have explicit features). 
The problem arises in many applications such as image recognition, signal processing or time series classification. 
We will focus on multiclass multivariate time series classification. 
In this setup time series are regarded as complex structured objects without explicit feature description. 
This is reasonable because we can't operate with original features as time series might be of different size, not aligned \cite{geurts2001pattern} or even multiscaled.

We investigate classification of accelerometer time series \cite{wang2014human}. The data is time series of acceleration from three axis, which is sensed by mobile phone or other portable device with accelerometer. 
The task is to predict the activity a person is performing. 
List of activities might include walking, running, sitting or walking up/down the stairs.

In general the problem of classifying complex structured objects can be split in two distinctive procedures. 
First, we need to extract informative features, and then we use those features as input to some classifier to obtain final model. 
For simplicity, we assume that these two procedures can be built and analyzed separately. 
In our project we focused mainly on comparing different methods of feature generation \cite{karasikov24feature, ivkin}. 
Extracted features can be later used for building classifiers and feature selection algorithms.

The first approach for feature generation is calculating expertly defined functions of time series \cite{kwapisz2011activity}. 
These functions include average value, standard deviation, mean absolute deviation and distribution for each component. 
We consider this approach a baseline, as it is the simplest method we use.

We compare baseline with more sophisticated parametric feature generation methods. 
One of them is autoregressive model \cite{lukashin2003adaptive}. 
For each time series we build parametric model and use those parameters as features for classification. 
We also consider the model of singular spectrum analysis of time series \cite{hassani2007singular}. 
We use eigenvalues of trajectory matrix as features for building classifier.

In the first part of these report we give definitions and make problem statement. In the second part we describe all of the proposed approaches in more detail. 
Last, we make the experiment on real accelerometer datasets \cite{wisdm, usc}, compare all methods and give conclusions and recommendations for practical use.

\section*{Problem Statement}
Let $\mathcal{S}$ be a space of complex structured objects, $Y$ is a finite set of class labels. 
Denote by $\mathfrak{D} = \{(s_i, y_i)\}_{i=1}^m$~-- given sample, where $s_i \in \mathcal{S}$ and $y_i \in Y$.

We consider the problem of recovering the function $f: \mathcal{S} \rightarrow Y$
\[
	y = f(s).
\]
Let $L(f, \mathfrak{D})$ be an error function which expresses the classification error of the function $f$ over the sample $\mathfrak{D}$. 
Our goal is to determine function $f^*$ which minimizes the error
\begin{equation}
	f^* = \argmin_{f} L(f, \mathfrak{D}).
	\label{eq::general_classification_task}
\end{equation}

We assume that the target function $f^*$ belongs to the class of function compositions $f = g \circ h$, where
\begin{itemize}
	\item 
	$h: \mathcal{S} \rightarrow H$ is a map from the original space $\mathcal{S}$ to the feature space $H \subset \mathbb{R}^n$;
	\item 
	$g: H \times \Theta \rightarrow Y$ is a parametric map from the feature space $H$ to the space of class labels $Y$. 
	The function $g$ is parametrized by a vector parameter $\boldsymbol{\theta} \in \Theta$. 
\end{itemize}

The determining of the function $f^*$ is equivalent to determining the functions $h^*$ and  $g^*$.

In this project we consider the following ways of generating the feature space~$H$:
\begin{itemize}
	\item 
	expert functions based on prior knowledge of the original objects. 
	These functions can be expressed as a set of statistics $\{h_i\}_{i=1}^n$, where $h_i: \mathcal{S} \rightarrow \mathbb{R}$.
	Thus, the description $\mathbf{h}$ of the object $s$ is the value of these statistics on the object 
	\[
		\mathbf{h} = h(s) = (h_1(s), \dots, h_n(s)).
	\]
	\item 
	hypothesis of data generation. 
	In this case the features are the estimated parameters of the considered hypothesis. 
	Let $S(s, \mathbf{h}, \boldsymbol{\lambda})$ be the error function which specifies the hypothesis, e.g. one could define the function $S$ as negative log-likelihood function [to do link]. 
	The optimal parameters $\widehat{\mathbf{h}}$ for object $s$ is obtained by
	\begin{equation}
		\widehat{\mathbf{h}} = \argmin_{\mathbf{h}} S( s, \mathbf{h}, \bm{\lambda}).
		\label{eq::optimal_description}
	\end{equation}
	The parameter $\bm{\lambda}$ is external structural parameter for the function $S$.
	The equation~\eqref{eq::optimal_description} determines the feature map $h:\mathcal{S} \rightarrow H$.
\end{itemize}

Given appropriate feature space $H$ and feature map $h$ we transform our original sample $\mathfrak{D} = \{s_i, y_i\}_{i=1}^m$ with complex structured objects to the new sample $\mathfrak{D}_H = \{\mathbf{h}_i, y_i\}_{i=1}^m$, where $\mathbf{h}_i = h(s_i) \in H$. 
The function $g(\mathbf{h}, \bm{\theta})$ is defined by its parameters vector $\bm{\theta} \in \Theta$. 
The optimal parameters~$\widehat{\bm{\theta}}$ are given by
\[
	\widehat{\bm{\theta}} = \argmin_{\bm{\theta}} L(g(\cdot, \bm{\theta}), \mathfrak{D}_H),
\]
where $L(\cdot, \cdot)$ is an analogue of the function~\eqref{eq::general_classification_task}.

In our project we consider accelerometer time series as complex objects. Time series is represented in following way:
\[
	s = (x_1, \dots, x_T) \in \mathcal{S},
\]
where $T$ denotes the length of time series. Now let us expand on different approaches of feature generation.

\section*{Feature generation}
\subsection*{Expert functions}
Given a set of complex objects $\{s_i\}_{i=1}^m$ we can extract features in a non-parametric way with a set of expert functions $\{h_j\}_{j=1}^n$. For time series~{\color{red} ![link]}, these functions could be mean, standard deviations, mean absolute deviations and distributions of the acceleration. The main drawback of this approach is that we are restricted by our choice of expert functions and for some types of data these functions might be impossible to derive.

\subsection*{Autoregressive model}
In this method we assume autoregressive model~{\color{red} ![link]} of the order $n$ as a hypothesis for generation of time series $s$. Each component of the object $s$ is a linear combination of the previous $n$ components 
\begin{equation*}
	x_t = w_0 + \sum_{j=1}^{n} w_j x_{t-j} + \epsilon_t,
\end{equation*}
where $\epsilon_t$ is a random noise. Prediction of the autoregressive model is defined by
\begin{equation}
	\hat{x}_t = w_0 + \sum_{j=1}^{n} w_j x_{t-j}.
	\label{eq::autoregression_prediction}
\end{equation}
For this method $n$ is a structural parameter and $\bm{\lambda} = n$. 

Feature description $\mathbf{h}$ of the object $s$ is given by optimal parameters of autoregressive model $\widehat{\mathbf{w}} = \{\widehat{w}_j\}_{j=0}^n$ for time series $s_i$. The hypothesis error function~\eqref{eq::optimal_description} in this case is the squared error between the original object $s$ and its prediction of the model~\eqref{eq::autoregression_prediction}. 

\begin{equation}
	\mathbf{h} = \widehat{\mathbf{w}} = \argmin_{\mathbf{w} \in \mathbb{R}^{n+1}} S(s, \mathbf{w}, \bm{\lambda}) = \argmin_{\mathbf{w} \in \mathbb{R}^{n+1}} \left( \sum_{t=n+1}^{T} \|x_t - \hat{x}_t\|^2\right).
	\label{eq::autoregression_description}
\end{equation}
The problem~\eqref{eq::autoregression_description} could be easily converted to the linear regression problem. Hence, for each initial time series $s$ we have to solve linear regression problem.

\subsection*{Singular spectrum analysis}
Alternative hypothesis for generation of time series is SSA (Singular Spectrum Analysis) model. We construct trajectory matrix for each time series $s=(x_1, \dots x_T)$:
\[
	\mathbf{X} = 
	\begin{pmatrix}
	x_1 & x_2 & \dots & x_n \\
	x_2 & x_3 & \dots & x_{n+1} \\
	\dots & \dots & \dots & \dots \\
	x_{T-n+1} & x_{T-n+2} & \dots & x_T
	\end{pmatrix}.
\]
Here $n$ is an external structural parameter.
Let find singular decomposition of matrix $\mathbf{X}^{\T} \mathbf{X}$:
\[
	\mathbf{X}^{\T} \mathbf{X} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^{\T},
\]
where $\mathbf{U}$ is a unitary matrix and $\Lambda = \text{diag}(\lambda_1, \dots, \lambda_n)$ whose entries $\lambda_i$ are eigenvalues of $\mathbf{X}^{\T} \mathbf{X}$. In this case we use the spectrum of the matrix $\mathbf{X}^{\T} \mathbf{X}$ as feature description $\mathbf{h}$ of the object $s$
\[
	\mathbf{h} = (\lambda_1, \dots, \lambda_n).
\]
\subsection*{Splines}
One could approximate the time series by splines~{\color{red} [link]}. Spline is defined by its parameters:
\begin{itemize}
	\item 
	$\{\xi_\ell\}_{\ell=1}^L$~--- the set of knots;
	\item 
	$\{\mathbf{w}_\ell\}_{\ell=1}^{L-1}$ ~--- parameters of the models are built on the interval $[\xi_\ell; \xi_{\ell + 1}]$. The dimension of each parameter vector $\mathbf{w}_{\ell}$ depends on the spline order.
\end{itemize}
The feature description of the time series could be assumed as union of these parameters.
\[
	\bm{h} = h(s) = (\xi_1, \dots, \xi_L, \mathbf{w}_1, \dots, \mathbf{w}_{L-1}).
\]

\subsection*{Classification}

{\color{red} describe accuracy score}

\subsection*{\color{red} TO DO}
\begin{itemize}
	\item the function $h$ is vectorial (discuss notations);
	\item add explanation(pics) of autoregressive model;
	\item splines;
	\item ts example pic.
\end{itemize}

\section*{Experiment}
In this paper we consider 2 different smart phone based datasets: WISDM~\cite{wisdm} and USC-HAD~\cite{usc}. Data from smart phone accelerometer consists of information about acceleration along each of three axis. Time difference between measurements equals 50 ms. Each time series belongs to one activity. The distributions of time series activities for each datasets are presented in Table~\ref{tbl::activities_distributions}.

\begin{table}
	\centering
	\caption{Activities distributions}
	\subfloat[WISDM]{
		\begin{tabular}{l|rr}
				\hline
				\textbf{Activity}   & \multicolumn{2}{l}{\textbf{\# objects}} \\
				\hline
				Standing   & 229 & 5.3\% \\
				Walking    & 1917 & 44.4\%\\
				Upstairs   & 466 &10.8\%\\
				Sitting    & 277  &6.4\%\\
				Jogging    & 1075 &24.9\%\\
				Downstairs & 357 &8.3\%\\
				\hline
			Total & \multicolumn{2}{l}{4321}  \\
			\hline
		\end{tabular}}
	\qquad
	\subfloat[USC-HAD]{
		\begin{tabular}{l|rr}
			\hline
			\textbf{Activity} & \multicolumn{2}{l}{\textbf{\# objects}} \\ \hline
			Walking-downstairs & 951 & 7\%  \\
			Walking-upstairs        & 1018&7.4\%  \\
			Walking-forward    & 1874&13.8\% \\
			Walking-right        & 1305&9.6\%  \\
			Walking-left        & 1280&9.4\%  \\
			Elevator-up        & 764&5.6\% \\
			Elevator-down        & 763&5.6\%  \\
			Standing           & 1167&8.6\%  \\
			Sitting            & 1294&9.5\%  \\
			Sleeping           & 1860&13.7\% \\
			Jumping        & 495&3.6\%  \\
			Running            & 849&6.2\%  \\ \hline 
			Total              & \multicolumn{2}{l}{13620}\\ 
			\hline
		\end{tabular}}
	\label{tbl::activities_distributions}
\end{table}

For each dataset we applied the feature generation approaches described above: expert functions, autoregressive model, SSA, splines. 
We used three different widely used classification model for each generated feature description: logistic regression, support vector machine and random forest. 
The external structural parameters for feature generation procedures,  such as the length $n$ for autoregression and the window width $n$ for SSA, {\color{red} !params for splines!}, were tuned using cross validation procedure. 
The hyperparameters for classification models were also tuned using cross validation procedure. 

Expert functions for time series {\color{red} TO DO}. 
Autoregressive parameters + SSA {\color{red} TO DO}.

We fit splines for time series using $scipy$~{\color{red} [link]} python library. The spline order equals 3. The knots $\{\xi_{\ell}\}_{\ell = 1}^L$ for  splines were distributed uniformly. The number $L$ were chosen implicitly by fitting smoothing parameter~$s$, it is possible because $L \sim \frac{1}{s}$. The fitting was constructed as follows. Firstly, there was the initialization step to find appropriate bounds for smoothing parameter. The next step is finding the smoothing parameter in this interval using bi-search approach.

The results of the experiments for the both datasets is presented in Figure~\ref{pic::accuracy_results}.

\begin{figure}[h]
	\centering
	\subfloat{
	\includegraphics[width=0.49\linewidth]{presentation/wisdm_methods.png}}
	\subfloat{
	\includegraphics[width=0.49\linewidth]{presentation/uschad_methods.png}}
	\caption{Accuracy scores}
	\label{pic::accuracy_results}
\end{figure}

We also carried out the experiment for union of all generated features. 

\begin{table}[!h]
	\centering
	\label{tbl::wisdm_union}
	\caption{Accuracy scores for WISDM dataset, all features}
	\begin{tabular}{c|c|c|c|c|c|c}
		\hline 
		 All	& Standing & Walking & Upstairs & Sitting & Jogging & Downstairs \\
		\hline
		 0.983 & 0.995 & 0.993 & 0.993 & 0.995 & 0.997 & 0.993 \\

		\hline 
	\end{tabular}
\end{table}

\bibliographystyle{unsrt}
\bibliography{ref.bib}
\end{document}
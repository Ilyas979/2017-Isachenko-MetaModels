\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{graphicx, epsfig}
\usepackage{amsmath,mathrsfs,amsfonts,amssymb}
\usepackage{subfig}
\usepackage{floatflt}
\usepackage{epic,ecltree}
\usepackage{mathtext}
\usepackage{fancybox}
\usepackage{fancyhdr}
\usepackage{bm}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{epstopdf}
\usepackage{multicol}
\usetheme{Copenhagen}%{Singapore}%{Warsaw}%{Warsaw}%{Darmstadt}
\usecolortheme{whale}
%\definecolor{beamer@blendedblue}{RGB}{15,120,80}

\newcommand{\T}{{\text{\tiny\sffamily\upshape\mdseries T}}}
%--------------------------------------------------------------------------------
\title[\hbox to 56mm{Human Activity Recognition  \hfill\insertframenumber\,/\,\inserttotalframenumber}]
{Generative models for human activity recognition}
\author[ROY team]{\\
	{\small \textbf{ROY team:} Ilya Zharikov, \\ \hspace{2.67cm}Roman Isachenko, \\ \hspace{2.61cm}Artem Bochkarev}}
\institute[SkolTech]{Skolkovo Institute of Science and Technology \\
	Machine Learning course 
	\vspace{0.3cm}
}
\date{March 20, 2017}
%--------------------------------------------------------------------------------
\begin{document}
	%--------------------------------------------------------------------------------
	\begin{frame}
		%\thispagestyle{empty}
		\titlepage
	\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Project goal}
		
		\begin{minipage}[t]{0.45\columnwidth}
			\begin{block}{Aim}
				Classification model for complex-structured objects.
			\end{block}
			
			\vspace{1.5cm}
			
			\textbf{Applications:}
			\begin{itemize}
				\item image processing;
				\item signal classification;
				\item topic modelling;
				\item \textit{time series analysis}.
			\end{itemize}
		\end{minipage}
		\hfill
		\begin{minipage}[t]{0.45\columnwidth}
			\begin{block}{Problem}
				Initial object has no appropriate feature description.
			\end{block}
			\begin{figure}[h]
				\centering
				\includegraphics[width=0.9\linewidth]{app_example.png}
				\label{ts_example}
			\end{figure}
		\end{minipage}
		
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Related work}
	\begin{enumerate}
		\item Wang W. et al. Human activity recognition using smart phone embedded sensors: A Linear Dynamical Systems method. \emph{Neural Networks (IJCNN), 2014 International Joint Conference on (pp. 1185-1190)}. IEEE.
		\vspace{\baselineskip}
		\item Kwapisz J.~R., Weiss G.~M., Moore S.~A. Activity recognition using cell phone accelerometers. \emph{ACM SigKDD Explorations Newsletter}, 12(2), 74-82, 2011
		\vspace{\baselineskip}
		\item Kuznetsov M. P., Ivkin N. P. Time series classification algorithm using combined feature description. \emph{Journal of Machine Learning and Data Analysis}, 2015.
	\end{enumerate}
	
\end{frame}
%--------------------------------------------------------------------------------
%\section{Problem Statement}
\begin{frame}{Problem Statement}
	\textbf{Let:} $s \in \mathcal{S}$~--- complex structured object;\\
	\hspace{24pt}$y \in Y$ - class label;
	\vfill
	\begin{block}{Task}
	Suppose to be given the set of labeled data $\mathfrak{D} = \{(s_i, y_i)\}_{i=1}^m$. \\Our goal is to determine function $f^*$, such that \vspace{-0.2cm}$$f^* = \arg \min_f L\left(f, \mathfrak{D}\right),\vspace{-0.3cm}$$ where $L(\cdot, \cdot)$ is an error function and $f: \mathcal{S} \rightarrow Y$.
	\end{block}
	\vfill
	\begin{block}{Approach}
		Suppose $f = g \circ h$, where
		\begin{enumerate}
			\item $h(s): \mathcal{S} \rightarrow H \subset \mathbb{R}^n$ is map from $\mathcal{S}$ into feature space $H$;
			\item $g(\bm{h}, \bm\theta): H \rightarrow Y$ is parametric map (classification model).
		\end{enumerate}
	\end{block}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Optimal parameters}
	
	\begin{minipage}[t]{0.15\columnwidth}
		\vspace{-0.6cm}
		\begin{block}{}
			\centering
			\vspace{0.5cm}
			$\,\,h(s)$
			\vspace{0.5cm}
		\end{block}
	\end{minipage}	
	\hfill
	\begin{minipage}[t]{0.8\columnwidth}
			Choice of feature map $h(s)$ by 
			\begin{itemize}
				\item prior (expert) knowledge;
				\item minimizing error functional.
			\end{itemize}
	\end{minipage}
\vfill
	\begin{minipage}[t]{0.15\columnwidth}
		\vspace{-0.6cm}
		\begin{block}{}
			\centering
			\vspace{1.3cm}
			$\,\,g(\bm{h}, \bm\theta)$
			\vspace{1.3cm}
		\end{block}
	\end{minipage}	
	\hfill
	\begin{minipage}[t]{0.8\columnwidth}
			Classification for $\{(\bm{h}_i , y_i)\}_{i=1}^m$
			\[
				\bm{\theta}^* = \arg \min_{\bm\theta} L(g, \bm\theta, \mathfrak{D}).
			\]
		E.g.: $g(\mathbf{h}, \bm\theta)$ - classification model;
		
		\hspace{0.9cm}$\bm\theta$ - model parameters;
				
		\hspace{0.9cm}$L (g, \bm\theta, \mathfrak{D})$ - classification error function.
	\end{minipage}	

	

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Time series example}
	\begin{figure}[h]
		\centering
		\includegraphics[width=1\linewidth]{ts_example.png}
		\label{ts_example}
	\end{figure}
\end{frame}
%--------------------------------------------------------------------------------
%\section{Feature extraction}
\begin{frame}{Expert functions}
	Prior knowledge about the objects could allow to choose the features.
	\begin{block}{Feature description}
		$\mathbf{h}_i = h(s_i)\in \mathbb{R}^{40}$~--- different statistics:
		\begin{itemize}
			\item average acceleration;
			\item standard deviation;
			\item mean absolute deviation;
			\item ...
		\end{itemize}
	\end{block}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Autoregressive model}
	\begin{block}{Data generation hypothesis}
		Time series $s = (x_1, \dots, x_T)$ is generated by autoregressive model
		\[
			\hat{x}_t = w_0 + \sum_{j=1}^n w_j x_{t-j}.
		\]
	\end{block}
	
	\begin{block}{Feature description}
		\[
			h(s_i) = \mathbf{w}^* = \arg \min_{\mathbf{w} \in \mathbb{R}^{n+1}} \sum_{j=n+1}^{T} \| x_j - \hat{x}_j \|^2.
		\]
	\end{block}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Singular Spectrum Analysis (SSA)}
	Trajectory matrix for time series $s = (x_1, \dots, x_T)$:
	\[
		\mathbf{X} = 
		\begin{pmatrix}
			x_1 & x_2 & \dots & x_n \\
			x_2 & x_3 & \dots & x_{n+1} \\
			\dots & \dots & \dots & \dots\\
			x_{T-n+1} & x_{T-n+2} & \dots & x_{T}
		\end{pmatrix}.
	\]
	
	\begin{block}{Feature description}
		\[
			h(s_i) = (\lambda_1, \dots ,\lambda_n),
		\]
		where $\{\lambda_i\}_{i=1}^n$ are eigenvalues of the matrix $\mathbf{X}^{\T} \mathbf{X}$, obtained by SVD decomposition
		\[
			\mathbf{X}^{\T} \mathbf{X} = \mathbf{V} \cdot \text{diag} (\lambda_1, \dots, \lambda_n) \cdot \mathbf{V}^{\T}.
		\]
	\end{block}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{(?!) Splines}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Data}
\noindent
\begin{minipage}[t]{0.45\linewidth}
	\textbf{WISDM}$^1$
	\begin{table}[]
		\small
		\label{my-label}
		\begin{tabular}{|l|c|}
			\hline
			Activity   & \# objects \\
			\hline
			Standing   & 229(5.3\%)  \\
			Walking    & 1917(44.4\%) \\
			Upstairs   & 466(10.8\%) \\
			Sitting    & 277(6.4\%)  \\
			Jogging    & 1075(24.9\%) \\
			Downstairs & 357(8.3\%) \\
			\hline
			Total & 4321  \\
			\hline
		\end{tabular}
	\end{table}

	\vspace{1cm}
	\medskip\hrule\medskip
	{\footnotesize $^1$http://www.cis.fordham.edu/wisdm/ \\
		$^2$http://sipi.usc.edu/HAD/}
	
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\linewidth}
	\textbf{USC-HAD}$^2$
	\begin{table}[]
		\small
		\label{my-label}
		\begin{tabular}{|l|c|}
			\hline
			Activity & \# objects \\ \hline
			Standing           & 1167(8.6\%)  \\
			Elevator-up        & 764(5.6\%)  \\
			Walking-forward    & 1874(13.8\%) \\
			Sitting            & 1294(9.5\%)  \\
			Walking-down & 951(7\%)  \\
			Sleeping           & 1860(13.7\%) \\
			Elevator-down        & 763(5.6\%)  \\
			Walking-upstairs        & 1018(7.4\%)  \\
			Jumping        & 495(3.6\%)  \\
			Walking-right        & 1305(9.6\%)  \\
			Walking-left        & 1280(9.4\%)  \\
			Running            & 849(6.2\%)  \\ \hline 
			Total              & 13620                                \\ \hline
		\end{tabular}
	\end{table}
\end{minipage}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Experiment}
	\begin{itemize}
		\item datasets: WISDM, USC-HAD;
		\item feature extraction methods: expert functions, autoregressive models, singular spectral analysis, splines;
		\item classification models: logistic regression, support vector machine, random forest;
		\item tuning parameters: cross-validation;
		\item quality measure: accuracy score.
	\end{itemize}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Results}
	\begin{table}[]
		\centering
		\label{my-label}
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			 & Expert & AutoReg & SSA & Splines\\
			\hline
			Log-Reg &    0.668    &    0.651     &   0.637  & 0.415  \\
			\hline
			SVM     &    0.797    &     0.655    &   0.822  & 0.740\\
			\hline
			RF      &    0.871    &     0.703    &  0.840 & 0.736 \\
			\hline
		\end{tabular}
	\end{table}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Feature union}

\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Conclusion}
	\begin{block}{Done}
		\begin{itemize}
			\item different approaches to classification of complex-structured objects were studied
			\item the results of experiments on human activities datasets outperform many previous methods
			\item 
		\end{itemize}
	\end{block}
	\begin{block}{Future work}
		\begin{itemize}
			\item new approaches to feature extraction (e.g. modified splines)
			\item implementing of structured learning methods
		\end{itemize}
	
	\end{block}
\end{frame}


\end{document} 